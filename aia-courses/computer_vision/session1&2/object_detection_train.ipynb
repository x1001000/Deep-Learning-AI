{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object detection API training with PET dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "這個 notebook 會教大家一步步的使用 tensorflow object detection API 來對 PET 這個資料集來進行訓練，使用原本 pre-train 在 COCO dataset 的 model 來進行 fine-tune。也可以參考[官方的說明](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/running_pets.md)\n",
    "\n",
    "主要的步驟其實不多，詳述如下：\n",
    "1. 下載 PET dataset，包含圖片與 label (annotations)\n",
    "2. 將 label 與圖片轉檔成 tf_record 格式 (tensorflow 記錄檔案的格式，會把圖片跟標籤融合在一起)\n",
    "3. 下載 pre-train 好的 model\n",
    "4. 修改官方的 config 檔 (告訴程式碼資料放在哪裡、訓練的參數等細節都在這個 config 檔)\n",
    "5. 設定好相關的環境變數\n",
    "6. 硬 train 一發囉！！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**先跟大家說聲抱歉，目前 hub 的 tensorflow 版本不夠新，大家執行到 train.py 的時候是一定會遇到錯誤的，之後我們會再試著更新 tensorflow 版本**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 下載 PET 資料集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget http://www.robots.ox.ac.uk/~vgg/data/pets/data/images.tar.gz\n",
    "!wget http://www.robots.ox.ac.uk/~vgg/data/pets/data/annotations.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!tar zxvf images.tar.gz\n",
    "!tar zxvf annotations.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!rm images.tar.gz\n",
    "!rm annotations.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 將 PET 的 label 與 images 轉檔為 tfrecord 的格式\n",
    "\n",
    "tfrecord 是一個 tensorflow 專用的儲存檔案格式，以二進位記錄檔案，詳細可參考[這篇文章](http://blog.csdn.net/jinbaosite/article/details/75194226)。要使用 tensorflow API 要把 label 跟 Image 都轉換成 tfrecord 才能夠使用。tensorflow 已經有寫好常用資料集 label 轉換成 tfrecord 的程式，但如果要用自己標注好的資料集來訓練，則需要自己撰寫 label 轉 tfrecord 的程式，詳細可參考[教學](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/using_your_own_dataset.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run object_detection/dataset_tools/create_pet_tf_record.py \\\n",
    "--label_map_path=object_detection/data/pet_label_map.pbtxt \\\n",
    "--data_dir= images/ \\\n",
    "--output_dir= data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 將資料統一放在 data 這個資料夾中\n",
    "!mv pet_train_with_masks.record object_detection/data/\n",
    "!mv pet_val_with_masks.record object_detection/data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 下載好 pre-train 的 model\n",
    "更多的模型可參考 [model zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md)，這邊我們下載 faster r-cnn，並使用 resnet 101 的 CNN 模型來提取特徵，這些模型都是已經在 COCO dataset 在 pre-train 過，基本上都已經有比較收斂的參數囉"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!wget http://storage.googleapis.com/download.tensorflow.org/models/object_detection/faster_rcnn_resnet101_coco_11_06_2017.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 解壓縮\n",
    "!tar zxvf faster_rcnn_resnet101_coco_11_06_2017.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 將模型中的 checkpoint 統一放在 data 這個資料夾中\n",
    "!cp faster_rcnn_resnet101_coco_11_06_2017/model.ckpt.* object_detection/data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 修改 model 的 config 檔\n",
    "要提供 training data 的位置在哪裡、model 的 ckpt 等等細節給 config 檔，才能夠進行訓練，config 檔會長成[這個樣子](https://github.com/tensorflow/models/blob/master/research/object_detection/samples/configs/faster_rcnn_resnet101_coco.config)，修改裡面的 **PATH_TO_BE_CONFIGURED**，改成我們統一放資料的那個資料夾路徑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 以這個 notebook 為例，要把路徑修改成剛剛統一放在 data 資料夾的路徑\n",
    "\"/home/jovyan/my_cv/session3&4/object_detection/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 把修改好的 config 檔案統一放在 data 這個資料夾中\n",
    "!cp object_detection/samples/configs/faster_rcnn_resnet101_pets.config \\\n",
    "object_detection/data/faster_rcnn_resnet101_pets.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 給定我們修改好的 config 檔位置\n",
    "PIPELINE_CONFIG = \"object_detection/data/faster_rcnn_resnet101_pets.config\"\n",
    "\n",
    "# 訓練結果放置路徑\n",
    "MY_MODEL_DIR=\"my_object_detect_model\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 設定相關環境變數\n",
    "讓環境能夠看到 /models/research 與 /models/research/slim\n",
    "\n",
    "若有問題可參考[連結](https://github.com/tensorflow/models/issues/1992)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!protoc object_detection/protos/*.proto --python_out=."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!export PYTHONPATH=$PYTHONPATH:`pwd`:`pwd`/slim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 開 train 拉！！\n",
    "給定 pipeline_config_path 與要儲存的 model 位置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run object_detection/train.py --logtostderr --pipeline_config_path=${PIPELINE_CONFIG}\\\n",
    "--train_dir=${MY_MODEL_DIR}/train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
